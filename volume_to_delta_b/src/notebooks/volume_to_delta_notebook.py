# Databricks notebook source
# MAGIC %md
# MAGIC # Volume to Delta - Notebook (Projeto B)
# MAGIC Este notebook lÃª dados de um volume Unity Catalog e escreve em uma tabela Delta.

# COMMAND ----------

# MAGIC %md
# MAGIC ## ConfiguraÃ§Ã£o dos ParÃ¢metros

# COMMAND ----------

# Widgets para receber parÃ¢metros
dbutils.widgets.text("catalog", "main", "CatÃ¡logo")
dbutils.widgets.text("schema", "default", "Schema")
dbutils.widgets.text("volume_name", "raw_data_b", "Volume de Origem")
dbutils.widgets.text("table_name", "processed_data_b", "Tabela de Destino")
dbutils.widgets.dropdown("file_format", "csv", ["csv", "json", "parquet", "delta", "avro"], "Formato dos Arquivos")
dbutils.widgets.dropdown("write_mode", "overwrite", ["overwrite", "append"], "Modo de Escrita")

# COMMAND ----------

# ObtÃ©m os valores dos parÃ¢metros
catalog = dbutils.widgets.get("catalog")
schema = dbutils.widgets.get("schema")
volume_name = dbutils.widgets.get("volume_name")
table_name = dbutils.widgets.get("table_name")
file_format = dbutils.widgets.get("file_format")
write_mode = dbutils.widgets.get("write_mode")

print(f"ğŸ“‚ CatÃ¡logo: {catalog}")
print(f"ğŸ“ Schema: {schema}")
print(f"ğŸ“¥ Volume: {volume_name}")
print(f"ğŸ“¤ Tabela: {table_name}")
print(f"ğŸ“ Formato: {file_format}")
print(f"ğŸ“ Modo: {write_mode}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ConstruÃ§Ã£o dos Caminhos

# COMMAND ----------

# Caminho do volume Unity Catalog
volume_path = f"/Volumes/{catalog}/{schema}/{volume_name}"
print(f"ğŸ“‚ Caminho do Volume: {volume_path}")

# Nome completo da tabela
full_table_name = f"{catalog}.{schema}.{table_name}"
print(f"ğŸ“‹ Nome da Tabela: {full_table_name}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Leitura dos Dados do Volume

# COMMAND ----------

# ConfiguraÃ§Ãµes de leitura por formato
read_configs = {
    "csv": {"header": "true", "inferSchema": "true", "sep": ","},
    "json": {"multiLine": "true"},
    "parquet": {},
    "delta": {},
    "avro": {}
}

# ObtÃ©m configuraÃ§Ãµes para o formato especificado
config = read_configs.get(file_format, {})

# Define o caminho de leitura
read_path = f"{volume_path}/*" if file_format != "delta" else volume_path

print(f"ğŸ“– Lendo dados de: {read_path}")
print(f"âš™ï¸  ConfiguraÃ§Ãµes: {config}")

# COMMAND ----------

# LÃª os dados
reader = spark.read.format(file_format)
for key, value in config.items():
    reader = reader.option(key, value)

df = reader.load(read_path)

print(f"âœ… Leitura concluÃ­da!")
print(f"ğŸ“Š Total de registros: {df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## VisualizaÃ§Ã£o dos Dados

# COMMAND ----------

# Mostra o schema
print("ğŸ“‹ Schema dos dados:")
df.printSchema()

# COMMAND ----------

# Mostra amostra dos dados
display(df.limit(10))

# COMMAND ----------

# MAGIC %md
# MAGIC ## Escrita na Tabela Delta

# COMMAND ----------

# Escreve na tabela Delta
print(f"ğŸ’¾ Escrevendo dados na tabela: {full_table_name}")
print(f"ğŸ“ Modo: {write_mode}")

df.write \
    .format("delta") \
    .mode(write_mode) \
    .saveAsTable(full_table_name)

print(f"âœ… Tabela {full_table_name} criada/atualizada com sucesso!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ValidaÃ§Ã£o

# COMMAND ----------

# Valida a tabela criada
result_df = spark.table(full_table_name)
print(f"ğŸ“Š Total de registros na tabela: {result_df.count()}")
display(result_df.limit(5))

