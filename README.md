# Solar - Multi-Project Databricks Asset Bundles

Este repositÃ³rio contÃ©m mÃºltiplos projetos DABs (Databricks Asset Bundles) independentes para processamento de dados.

## ğŸ“ Estrutura do RepositÃ³rio

```
Solar/
â”œâ”€â”€ README.md                           # Este arquivo
â”œâ”€â”€ .gitignore
â”œâ”€â”€ projects/
â”‚   â”œâ”€â”€ volume_to_delta_a/              # Projeto A
â”‚   â”‚   â”œâ”€â”€ databricks.yml
â”‚   â”‚   â”œâ”€â”€ resources/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â””â”€â”€ volume_to_delta_b/              # Projeto B
â”‚       â”œâ”€â”€ databricks.yml
â”‚       â”œâ”€â”€ resources/
â”‚       â”œâ”€â”€ src/
â”‚       â””â”€â”€ tests/
```

## ğŸš€ Como Usar

Cada projeto DABs Ã© **independente** e deve ser executado a partir do seu prÃ³prio diretÃ³rio.

### Projeto A

```bash
# Navegar para o projeto A
cd projects/volume_to_delta_a

# Validar o bundle
databricks bundle validate

# Deploy no ambiente dev
databricks bundle deploy --target dev

# Executar o job
databricks bundle run volume_to_delta
```

### Projeto B

```bash
# Navegar para o projeto B
cd projects/volume_to_delta_b

# Validar o bundle
databricks bundle validate

# Deploy no ambiente dev
databricks bundle deploy --target dev

# Executar o job
databricks bundle run volume_to_delta
```

## ğŸ”§ Comandos Ãšteis

### Deploy de todos os projetos (script)

```bash
# Deploy de todos os projetos em dev
for project in projects/*/; do
    echo "ğŸ“¦ Deploying: $project"
    cd "$project"
    databricks bundle deploy --target dev
    cd ../..
done
```

### Executar projeto especÃ­fico com parÃ¢metros

```bash
cd projects/volume_to_delta_a
databricks bundle run volume_to_delta \
  --var "catalog=meu_catalogo" \
  --var "schema=meu_schema" \
  --var "volume_name=meus_dados" \
  --var "table_name=minha_tabela"
```

## ğŸ“‹ Projetos DisponÃ­veis

| Projeto | DescriÃ§Ã£o | PadrÃµes |
|---------|-----------|---------|
| `volume_to_delta_a` | ETL Volume â†’ Delta | `raw_data_a` â†’ `processed_data_a` |
| `volume_to_delta_b` | ETL Volume â†’ Delta | `raw_data_b` â†’ `processed_data_b` |

## âš™ï¸ ConfiguraÃ§Ã£o dos Targets

Todos os projetos possuem 3 targets prÃ©-configurados:

| Target | Modo | DescriÃ§Ã£o |
|--------|------|-----------|
| `dev` | development | Ambiente de desenvolvimento (padrÃ£o) |
| `staging` | development | Ambiente de staging |
| `prod` | production | Ambiente de produÃ§Ã£o |

### VariÃ¡veis Comuns

| VariÃ¡vel | DescriÃ§Ã£o |
|----------|-----------|
| `catalog` | CatÃ¡logo Unity Catalog |
| `schema` | Schema onde a tabela serÃ¡ criada |
| `volume_name` | Nome do volume de origem |
| `table_name` | Nome da tabela Delta de destino |
| `file_format` | Formato dos arquivos (csv, json, parquet) |

## ğŸ” ConfiguraÃ§Ã£o do Databricks CLI

### OpÃ§Ã£o 1: ConfiguraÃ§Ã£o interativa

```bash
databricks configure
```

### OpÃ§Ã£o 2: VariÃ¡veis de ambiente

```bash
export DATABRICKS_HOST="https://seu-workspace.databricks.com"
export DATABRICKS_TOKEN="seu-token"
```

### OpÃ§Ã£o 3: Arquivo de configuraÃ§Ã£o (~/.databrickscfg)

```ini
[DEFAULT]
host = https://seu-workspace.databricks.com
token = seu-token
```

## ğŸ†• Adicionando Novos Projetos

1. Copie um projeto existente:
```bash
cp -r projects/volume_to_delta_a projects/meu_novo_projeto
```

2. Edite o `databricks.yml`:
   - Altere o `bundle.name`
   - Ajuste as variÃ¡veis padrÃ£o

3. Personalize os arquivos em `src/` e `resources/`

4. Valide e faÃ§a deploy:
```bash
cd projects/meu_novo_projeto
databricks bundle validate
databricks bundle deploy
```

## ğŸ“š DocumentaÃ§Ã£o

- [Databricks Asset Bundles](https://docs.databricks.com/en/dev-tools/bundles/index.html)
- [Unity Catalog Volumes](https://docs.databricks.com/en/connect/unity-catalog/volumes.html)
- [Databricks CLI](https://docs.databricks.com/en/dev-tools/cli/index.html)

## ğŸ“„ LicenÃ§a

MIT License
